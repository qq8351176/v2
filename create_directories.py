'''
Usage:
    python create_directories.py -n <project_directory_name>
    or
    python create_directories.py --name <project_directory_name>

Directory Tree:
    TensorFlow
    ├─ addons
    │   └── labelImg
    ├─ models
    │   ├── official
    │   ├── research
    │   ├── samples
    │   └── tutorials
    ├─ scripts
    │   └─ preprocessing
    │       ├─ generate_tfrecord.py
    │       └─ xml_to_csv.py
    └─ workspaces
        ├─ create_directories.py
        └─ project_directory_name <- 自定义文件夹名称
            ├─ annotations
            ├─ evaluation
            ├─ images
            │   ├─ eval
            │   ├─ test
            │   └─ train
            ├─ pre_trained_model
            ├─ training
            │   └─ ssd_inception_v2_coco.config
            └─ README.md
'''

import os
import shutil
import re
import argparse

def main():
    # 验证create_directories.py脚本是否在/workspaces文件夹下
    pattern = re.compile(r".+workspaces$")
    if re.match(pattern, os.getcwd().replace('\\', '/')) is None:
        print("请将create_directories.py脚本放置在workspaces文件夹下。")
        return

    # 创建项目文件夹及其子文件夹
    parser = argparse.ArgumentParser()
    parser.add_argument("-n",
                        "--name",
                        help="项目文件夹名称",
                        type=str)
    args = parser.parse_args()
    if args.name is None:
        print("请输入项目文件夹名称。（python create_directories.py -n <project_directory_name>）")
        return
    if os.path.exists(args.name):
        print("%s文件夹已存在，请使用其他名称。" %args.name)
        return
    os.mkdir(args.name)
    os.mkdir(args.name + "/annotations")
    os.mkdir(args.name + "/evaluation")
    os.mkdir(args.name + "/images")
    os.mkdir(args.name + "/images/eval")
    os.mkdir(args.name + "/images/test")
    os.mkdir(args.name + "/images/train")
    os.mkdir(args.name + "/pre_trained_model")
    os.mkdir(args.name + "/trained_frozen_models")
    os.mkdir(args.name + "/training")
    f = open(args.name + "/README.md", "w")
    f.close()
    os.chdir("../")  # 到TensorFlow文件夹下
    src_config_file = "models/research/object_detection/samples/configs/ssd_inception_v2_coco.config"
    dst_config_file = "workspaces/%s/training/ssd_inception_v2_coco.config" %args.name
    if os.path.exists(src_config_file):
        shutil.copy(src_config_file, dst_config_file)
    else:
        print("models/research/object_detection/samples/configs/ssd_inception_v2_coco.config文件不存在。")
        return
    src_train_script = "models/research/object_detection/legacy/train.py"
    dst_train_script = "workspaces/%s/train.py" %args.name
    if os.path.exists(src_train_script):
        shutil.copy(src_train_script, dst_train_script)
    else:
        print("models/research/object_detection/legacy/train.py文件不存在。")
        return

    # 检测scripts文件夹及其下脚本是否存在
    if not os.path.exists("scripts"):
        os.mkdir("scripts")
    if not os.path.exists("scripts/preprocessing"):
        os.mkdir("scripts/preprocessing")
    if not os.path.exists("scripts/preprocessing/xml_to_csv.py"):
        with open("scripts/preprocessing/xml_to_csv.py", "w") as f:
            f.write('"""\nUsage:\n# Create train data:\npython xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/train -o [PATH_TO_ANNOTATIONS_FOLDER]/train_labels.csv\n\n# Create test data:\npython xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/test -o [PATH_TO_ANNOTATIONS_FOLDER]/test_labels.csv\n"""\n\nimport os\nimport glob\nimport pandas as pd\nimport argparse\nimport xml.etree.ElementTree as ET\n\n\ndef xml_to_csv(path):\n    """Iterates through all .xml files (generated by labelImg) in a given directory and combines them in a single Pandas datagrame.\n\n    Parameters:\n    ----------\n    path : {str}\n        The path containing the .xml files\n    Returns\n    -------\n    Pandas DataFrame\n        The produced dataframe\n    """\n\n    xml_list = []\n    for xml_file in glob.glob(path + \'/*.xml\'):\n        tree = ET.parse(xml_file)\n        root = tree.getroot()\n        for member in root.findall(\'object\'):\n            value = (root.find(\'filename\').text,\n                    int(root.find(\'size\')[0].text),\n                    int(root.find(\'size\')[1].text),\n                    member[0].text,\n                    int(member[4][0].text),\n                    int(member[4][1].text),\n                    int(member[4][2].text),\n                    int(member[4][3].text)\n                    )\n            xml_list.append(value)\n    column_name = [\'filename\', \'width\', \'height\',\n                \'class\', \'xmin\', \'ymin\', \'xmax\', \'ymax\']\n    xml_df = pd.DataFrame(xml_list, columns=column_name)\n    return xml_df\n\n\ndef main():\n    # Initiate argument parser\n    parser = argparse.ArgumentParser(\n        description="Sample TensorFlow XML-to-CSV converter")\n    parser.add_argument("-i",\n                        "--inputDir",\n                        help="Path to the folder where the input .xml files are stored",\n                        type=str)\n    parser.add_argument("-o",\n                        "--outputFile",\n                        help="Name of output .csv file (including path)", type=str)\n    args = parser.parse_args()\n\n    if(args.inputDir is None):\n        args.inputDir = os.getcwd()\n    if(args.outputFile is None):\n        args.outputFile = args.inputDir + "/labels.csv"\n\n    assert(os.path.isdir(args.inputDir))\n\n    xml_df = xml_to_csv(args.inputDir)\n    xml_df.to_csv(\n        args.outputFile, index=None)\n    print(\'Successfully converted xml to csv.\')\n\n\nif __name__ == \'__main__\':\n    main()')
    if not os.path.exists("scripts/preprocessing/generate_tfrecord.py"):
        with open("scripts/preprocessing/generate_tfrecord.py", "w") as f:
            f.write('"""\nUsage:\n\n# Create train data:\npython generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/train_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record\n\n# Create test data:\npython generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/test_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record\n"""\n\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport os\nimport io\nimport pandas as pd\nimport tensorflow as tf\nimport sys\nsys.path.append("../../models/research")\n\nfrom PIL import Image\nfrom object_detection.utils import dataset_util\nfrom collections import namedtuple, OrderedDict\n\nflags = tf.app.flags\nflags.DEFINE_string(\'csv_input\', \'\', \'Path to the CSV input\')\nflags.DEFINE_string(\'output_path\', \'\', \'Path to output TFRecord\')\nflags.DEFINE_string(\'label\', \'\', \'Name of class label\')\n# if your image has more labels input them as\n# flags.DEFINE_string(\'label0\', \'\', \'Name of class[0] label\')\n# flags.DEFINE_string(\'label1\', \'\', \'Name of class[1] label\')\n# and so on.\nflags.DEFINE_string(\'img_path\', \'\', \'Path to images\')\nFLAGS = flags.FLAGS\n\n\n# TO-DO replace this with label map\n# for multiple labels add more else if statements\ndef class_text_to_int(row_label):\n    if row_label == FLAGS.label:  # \'ship\':\n        return 1\n    # comment upper if statement and uncomment these statements for multiple labelling\n    # if row_label == FLAGS.label0:\n    #   return 1\n    # elif row_label == FLAGS.label1:\n    #   return 0\n    else:\n        None\n\n\ndef split(df, group):\n    data = namedtuple(\'data\', [\'filename\', \'object\'])\n    gb = df.groupby(group)\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n\n\ndef create_tf_example(group, path):\n    with tf.gfile.GFile(os.path.join(path, \'{}\'.format(group.filename)), \'rb\') as fid:\n        encoded_jpg = fid.read()\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = Image.open(encoded_jpg_io)\n    width, height = image.size\n\n    filename = group.filename.encode(\'utf8\')\n    image_format = b\'jpg\'\n    # check if the image format is matching with your images.\n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    classes_text = []\n    classes = []\n\n    for index, row in group.object.iterrows():\n        xmins.append(row[\'xmin\'] / width)\n        xmaxs.append(row[\'xmax\'] / width)\n        ymins.append(row[\'ymin\'] / height)\n        ymaxs.append(row[\'ymax\'] / height)\n        classes_text.append(row[\'class\'].encode(\'utf8\'))\n        classes.append(class_text_to_int(row[\'class\']))\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        \'image/height\': dataset_util.int64_feature(height),\n        \'image/width\': dataset_util.int64_feature(width),\n        \'image/filename\': dataset_util.bytes_feature(filename),\n        \'image/source_id\': dataset_util.bytes_feature(filename),\n        \'image/encoded\': dataset_util.bytes_feature(encoded_jpg),\n        \'image/format\': dataset_util.bytes_feature(image_format),\n        \'image/object/bbox/xmin\': dataset_util.float_list_feature(xmins),\n        \'image/object/bbox/xmax\': dataset_util.float_list_feature(xmaxs),\n        \'image/object/bbox/ymin\': dataset_util.float_list_feature(ymins),\n        \'image/object/bbox/ymax\': dataset_util.float_list_feature(ymaxs),\n        \'image/object/class/text\': dataset_util.bytes_list_feature(classes_text),\n        \'image/object/class/label\': dataset_util.int64_list_feature(classes),\n    }))\n    return tf_example\n\n\ndef main(_):\n    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n    path = os.path.join(os.getcwd(), FLAGS.img_path)\n    examples = pd.read_csv(FLAGS.csv_input)\n    grouped = split(examples, \'filename\')\n    for group in grouped:\n        tf_example = create_tf_example(group, path)\n        writer.write(tf_example.SerializeToString())\n\n    writer.close()\n    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n    print(\'Successfully created the TFRecords: {}\'.format(output_path))\n\n\nif __name__ == \'__main__\':\n    tf.app.run()')

    print("Successfully create %s and its subdirectories.\n" %args.name)
    return


if __name__ == '__main__':
    main()